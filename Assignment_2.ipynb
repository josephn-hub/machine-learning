{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1a2962-2bfa-4205-9feb-c82cf6e634d9",
   "metadata": {},
   "source": [
    "### 1. How do the assumptions of linear regression influence model accuracy, and how would you check for their validity in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098d5a7-ea77-479f-9cf3-55dc3a5de029",
   "metadata": {},
   "source": [
    "The assumptions of linear regression are foundational for the model's performance, accuracy, and validity of results. \n",
    "If there are violations of these assumptions can reduce predictive power, mislead interpretations, or result in inefficient estimations. \n",
    "\n",
    "1. Linearity of the Relationship\n",
    "Assumption: The relationship between the independent variables and the dependent variable is linear.\n",
    "Influence on Accuracy: Linear regression assumes that any change in the predictor variables has a consistent, proportional change in the response variable. If the actual relationship is non-linear, the model may underfit, failing to capture the true relationship, leading to poor predictions and biased estimates.\n",
    "• Checking Validity:\n",
    "Scatter Plots: Plot each predictor against the response variable. Patterns that are curved or show complex interactions may indicate non-linearity.\n",
    "\n",
    "2. Independence of Errors\n",
    "Assumption: The residuals (errors) should be independent of each other.\n",
    "Influence on Accuracy: When observations are correlated, as in time series data, the model can underestimate error, leading to over-optimistic results. This is particularly problematic in sequential or clustered data where errors may follow a pattern.\n",
    "• Checking Validity:\n",
    "Durbin-Watson Test: Primarily for time series data, this test detects autocorrelation in residuals. A value close to 2 indicates no autocorrelation.\n",
    "Residuals Plot Over Time: For time-dependent data, plot residuals over time to observe any patterns that suggest dependency.\n",
    "\n",
    "4. Normality of Errors\n",
    "Assumption: Residuals should be normally distributed, especially important in small samples for valid hypothesis tests and confidence intervals.\n",
    "Influence on Accuracy: Non-normally distributed errors affect the accuracy of p-values and confidence intervals, potentially leading to incorrect inferences about predictors.\n",
    "Checking Validity:\n",
    "Q-Q Plot: A quantile-quantile plot of residuals shows if they align closely with a normal distribution.\n",
    "\n",
    "Practical Implications of Assumption Violations:\n",
    "Biased Estimates: Linear relationships and independence violations can bias estimates, particularly when errors or relationships aren’t as assumed.\n",
    "Reduced Predictive Accuracy: Heteroscedasticity and multicollinearity often affect prediction accuracy, making models less generalizable.\n",
    "Unreliable Statistical Inference: Non-normality of errors or heteroscedasticity can lead to unreliable p-values, confidence intervals, and hypothesis tests.\n",
    "Ensuring these assumptions hold is essential to producing reliable, interpretable linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da7e71-9728-44ba-b46c-fb887ff750cb",
   "metadata": {},
   "source": [
    "### 2. If you had a dataset prone to overfitting, which regularization technique would you apply in linear regression: Lasso orRidge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c019d-b36e-456c-952a-5b29e24f5071",
   "metadata": {},
   "source": [
    "Overfitting in linear regression:\n",
    "Both Lasso and Ridge regularization are effective techniques to reduce complexity and improve model generalizability even though each works differently and is suited to different scenarios.\n",
    "\n",
    "1. Ridge Regression (L2 Regularization)\n",
    "How it Works: Ridge regression penalizes the sum of squared coefficients by adding an term α×∑βj2 to the cost function. This term discourages large coefficients, effectively \"shrinking\" them towards zero but generally not making them exactly zero.\n",
    "Best For: Ridge is ideal when you have many predictors, especially if they are not sparse (meaning most features contribute somewhat to the response). It works well in cases where the predictors have small but meaningful contributions and where multicollinearity (high correlation between predictors) might be an issue.\n",
    "Impact on Overfitting: By shrinking coefficients, Ridge reduces the model’s sensitivity to noise, which helps with overfitting, but it retains all predictors to some degree.\n",
    "Example Use Case: Ridge regression is often preferred for datasets where all predictors are believed to be relevant but the model needs smoothing.\n",
    "\n",
    "2. Lasso Regression (L1 Regularization)\n",
    "How it Works: Lasso adds an α×∑∣βj ∣penalty to the cost function, encouraging some coefficients to become exactly zero, thus performing feature selection.\n",
    "Best For: Lasso is particularly effective if you believe that only a subset of predictors are truly relevant, as it drives irrelevant feature coefficients to zero. This makes it well-suited for high-dimensional datasets where some features are likely irrelevant.\n",
    "Impact on Overfitting: By simplifying the model and reducing the number of features, Lasso mitigates overfitting by limiting complexity and focusing only on the most significant predictors.\n",
    "Example Use Case: Lasso is often the better choice for sparse datasets or when you aim to reduce the number of predictors for interpretability.\n",
    "\n",
    "• Choosing Between Lasso and Ridge\n",
    "If all predictors are likely relevant but the model overfits, Ridge may be more suitable since it smooths coefficient sizes without removing features.\n",
    "If only a few predictors are likely relevant, Lasso is preferable as it can eliminate irrelevant features, resulting in a simpler and more interpretable model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16faa9e0-2491-47fc-9e0f-b7c86e3359df",
   "metadata": {},
   "source": [
    "### 3. Describe a scenario where logistic regression would be more apt than K-Nearest Neighbors for a classification task. How does the sigmoid function influence predictions in this context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba94de-8c03-4f69-b40d-4650d9c46d5b",
   "metadata": {},
   "source": [
    "Logistic regression would be more useful than K-Nearest Neighbors (KNN) for a classification task in scenarios where interpretability, computational efficiency, and linearity of the decision boundary are priorities.\n",
    "\n",
    "• Large Datasets: Logistic regression is computationally efficient and scales well with large datasets. KNN, on the other hand, becomes slower as the dataset grows, as it has to calculate the distance between the test point and every other point in the training set.\n",
    "\n",
    "• High Dimensionality: Logistic regression is often preferable when there are many features, especially if the data is sparse (e.g., text classification tasks). KNN can struggle with high-dimensional spaces due to the \"curse of dimensionality,\" where the distance metric becomes less meaningful as dimensions increase.\n",
    "\n",
    "• Linearly Separable Data: Logistic regression assumes a linear decision boundary, which can be a strength when the data is linearly separable or close to it. In cases like determining if an email is spam or not, logistic regression can be highly effective if the features indicate a strong linear relationship.\n",
    "\n",
    "• Need for Interpretability: Logistic regression provides interpretable results by estimating the probability of class membership. This probability output can be useful for decision-making, and the model’s coefficients show the relationship between features and the outcome, unlike KNN, which is less interpretable.\n",
    "\n",
    "• Regularization: Logistic regression can be regularized using L1 (Lasso) or L2 (Ridge) penalties to handle multicollinearity or reduce overfitting, which is beneficial for high-dimensional data. KNN lacks this capability, and overfitting is controlled only by adjusting \n",
    "k, the number of neighbors.\n",
    "\n",
    "• Role of the Sigmoid Function in Logistic Regression\n",
    "In logistic regression, the sigmoid function transforms the linear combination of input features into a probability value between 0 and 1. Here’s how it works:\n",
    "\n",
    "Log-Odds Transformation: Logistic regression models the log-odds of the probability of an event (e.g., defaulting on a loan) as a linear function of the features:\n",
    "log-odds(p)=β0 +β1 x1 +β2 x2 +⋯+βn xn\n",
    "​\n",
    "Sigmoid Transformation: To convert the log-odds into a probability, the sigmoid function is applied:\n",
    "\n",
    "p(y=1∣X)=1/1+e−(β0 +β1 x1 +⋯+βn xn )\n",
    "\n",
    "This maps the output to the range (0,1), allowing it to be interpreted as the probability of the positive class.\n",
    "\n",
    "\n",
    "Threshold-Based Decision: By setting a threshold (e.g., 0.5), predictions are classified into binary outcomes. If the output probability is greater than 0.5, the prediction is classified as the positive class; otherwise, it’s classified as the negative class.\n",
    "\n",
    "Useful for below cases:\n",
    "Probability Prediction\n",
    "Decision Boundary\n",
    "Interpretation of Coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddeb4b-70f1-42c6-a7ae-5e983c380674",
   "metadata": {},
   "source": [
    "### 4. Compare the evaluation metrics for regression and classification. Why might you choose Mean Absolute Error over R² for a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12fe96-845c-48a6-b237-2748beca2d82",
   "metadata": {},
   "source": [
    "In regression and classification tasks, evaluation metrics assess model performance based on the nature of the predictions.\n",
    "\n",
    "1. Evaluation Metrics for Regression\n",
    "   \n",
    "• Mean Absolute Error (MAE): MAE calculates the average of absolute differences between actual and predicted values. It provides a direct measure of error in the same units as the data, making it straightforward and easy to interpret.\n",
    "\n",
    "• Mean Squared Error (MSE): MSE calculates the average of the squared differences between predicted and actual values. Squaring penalizes larger errors more than smaller ones, which is useful when large errors are particularly undesirable.\n",
    "\n",
    "• Root Mean Squared Error (RMSE): RMSE is the square root of MSE, maintaining the same units as the data and amplifying large errors. It is often used to interpret model accuracy with fewer biases.\n",
    "R-squared (R²): represents the proportion of variance explained by the model, indicating goodness of fit. It ranges from 0 to 1, where values closer to 1 imply a better fit. \n",
    "\n",
    " R² is a relative measure, and its value depends on the variance in the data.\n",
    "When to Prefer MAE over R²:\n",
    "Interpretability: MAE directly reflects the average error, making it more interpretable in terms of how much error to expect on average.\n",
    "\n",
    "R²can be less reliable in models with fewer predictors, where it might overestimate fit. MAE suitable for a simple, absolute measure of prediction error regardless of dataset complexity.\n",
    "\n",
    "2. Evaluation Metrics for Classification\n",
    "   \n",
    "• Accuracy: Accuracy is the percentage of correctly classified instances out of the total. It is straightforward but may not be informative if classes are imbalanced.\n",
    "• Precision, Recall, and F1 Score:\n",
    "Precision measures the accuracy of positive predictions (True Positives / (True Positives + False Positives)).\n",
    "Recall (or Sensitivity) measures the proportion of actual positives that were correctly predicted (True Positives / (True Positives + False Negatives)).\n",
    "• F1 Score balances precision and recall, useful in cases of class imbalance.\n",
    "\n",
    "\n",
    "Choosing Between Metrics\n",
    "For regression, MAE is often chosen over R²:\n",
    "Simplicity and Interpretability are Key: MAE’s straightforward error measure is beneficial when stakeholders or users need a clear, direct interpretation of error.\n",
    "Outliers Are Present: MAE is less impacted by outliers, making it preferable if the dataset contains anomalies that could skew results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8847594f-201d-475b-8d62-82cd698e8252",
   "metadata": {},
   "source": [
    "### 5. When would you prefer to use a Support Vector Machine over a Decision Tree for classification, considering the nature of the data and computational efficiency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36202736-3701-4504-a6c5-6fe931566a52",
   "metadata": {},
   "source": [
    "\n",
    "1. High-Dimensional Data\n",
    "   \n",
    "• SVM Advantage: SVMs are generally well-suited for high-dimensional datasets, such as text data or image recognition, where there are many features relative to the number of samples. SVM can effectively find the hyperplane that maximizes the margin between classes, even in high-dimensional spaces.\n",
    "\n",
    "• Decision Tree Limitation: Decision Trees can struggle in high-dimensional data without a large sample size because they may overfit to noise or require extensive depth to capture the decision boundaries.\n",
    "\n",
    "3. Linearly Separable Data or Clear Decision Boundaries\n",
    "   \n",
    "• SVM Advantage: If the data is linearly separable or nearly so, SVM can find the optimal separating hyperplane, leading to better generalization. Even for non-linear separability, using kernel functions (such as the radial basis function, or RBF) enables SVMs to model complex boundaries.\n",
    "\n",
    "• Decision Tree Limitation: Decision Trees often create axis-aligned splits, which may not capture complex or non-linear decision boundaries as effectively as SVM with a kernel.\n",
    "\n",
    "5. Robustness Against Overfitting\n",
    "   \n",
    "• SVM Advantage: SVM is generally less prone to overfitting, especially with a proper regularization parameter and kernel choice. SVM aims to maximize the margin around the decision boundary, which leads to better generalization, especially on smaller datasets.\n",
    "\n",
    "• Decision Tree Limitation: Decision Trees are more prone to overfitting, especially without pruning, as they tend to capture the exact details of the training data, including noise.\n",
    "\n",
    "7. Small to Medium Dataset Size\n",
    "   \n",
    "• SVM Advantage: SVMs can be computationally expensive for very large datasets, particularly in non-linear cases with kernels. For small to medium-sized datasets, however, SVMs are feasible and efficient, and they tend to produce robust models.\n",
    "\n",
    "• Decision Tree Advantage on Large Data: Decision Trees are generally faster to train and more scalable to large datasets. They can be less computationally intensive and are well-suited for massive datasets when combined with ensemble techniques (e.g., Random Forests), which further improve their robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1da025-2457-4f95-9e50-0c584b8038ef",
   "metadata": {},
   "source": [
    "### 6. Explain the key differences between bagging and boosting. In which scenario would Adaboost be more beneficial than Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc9e35-cb8f-4e11-a90a-ecbe377838c9",
   "metadata": {},
   "source": [
    "Bagging and Boosting are two ensemble techniques that combine multiple models to improve overall performance.\n",
    "\n",
    "1. Bagging (Bootstrap Aggregating)\n",
    " Bagging builds multiple independent models by training each on a random subset of the dataset (with replacement). It averages the predictions from these models, reducing variance and enhancing stability.\n",
    "Key Model - Random Forest: A popular bagging method is the Random Forest, which uses multiple decision trees trained on random samples with random feature subsets, resulting in a robust, high-performing ensemble. Since each tree is independent, Random Forest is less sensitive to noise and less prone to overfitting.\n",
    "When Bagging is Effective:\n",
    "\n",
    "Bagging is beneficial when the base model is prone to high variance, such as a single decision tree. By averaging many models, it reduces overfitting, making it ideal for high-variance, complex datasets.\n",
    "Random Forest works well in cases where interpretability is less important than predictive power, and the data has sufficient size and features.\n",
    "\n",
    "2. Boosting\n",
    " Boosting, unlike bagging, builds models sequentially. Each model learns from the errors of the previous one, giving more weight to misclassified points. This iterative process creates a strong learner by correcting errors step-by-step, making boosting sensitive to data characteristics.\n",
    "Key Model - AdaBoost: AdaBoost (Adaptive Boosting) is a popular boosting technique. It starts with a weak model (often a decision stump) and iteratively adjusts the weights of misclassified points, refining the model with each step. AdaBoost’s focus on hard-to-classify points can lead to high accuracy on complex datasets.\n",
    "When Boosting is Effective:\n",
    "\n",
    "Boosting is beneficial in cases where the data has subtle patterns that require a focus on more difficult-to-predict examples. It tends to outperform bagging when the primary goal is accuracy, and the data isn’t excessively noisy.\n",
    "\n",
    "AdaBoost is particularly useful for binary classification tasks or datasets with clear but complex decision boundaries, where each iteration can correct previous mistakes and improve precision.\n",
    "\n",
    "Smaller, Less Noisy Datasets: AdaBoost can achieve high accuracy on smaller datasets by refining mistakes across rounds. However, it’s sensitive to noise, so it’s less effective on noisy data or cases with many outliers, where Random Forest’s robustness would be more beneficial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526b1de-b7e2-4650-abeb-78d7e17ad681",
   "metadata": {},
   "source": [
    "### 7. Using the `California housing` dataset from sklearn, demonstrate how you'd implement multiple linear regression. Check for assumptions of linear regression and apply necessary regularization techniques if required. How would you interpret the performance using regression evaluation metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30a7d84c-d741-4561-991b-4925b6f2ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Prepare the Data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "#Train-Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67004795-d7eb-4a33-9775-a6019b2c891e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implement Multiple Linear Regression\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f72ffd2-313b-46bb-9fe9-2a6189518c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature         VIF\n",
      "0      MedInc   11.511140\n",
      "1    HouseAge    7.195917\n",
      "2    AveRooms   45.993601\n",
      "3   AveBedrms   43.590314\n",
      "4  Population    2.935745\n",
      "5    AveOccup    1.095243\n",
      "6    Latitude  559.874071\n",
      "7   Longitude  633.711654\n"
     ]
    }
   ],
   "source": [
    "#Multicollinearity: Features should ideally not be highly correlated. Use variance inflation factor (VIF) to check for multicollinearity.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ac203bb-118d-48fe-8a7b-289a16eea1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lasso<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply Regularization (if needed)\n",
    "#If high multicollinearity is found, or if the model overfits, you can use Ridge or Lasso regularization to improve model performance.\n",
    "\n",
    "# Using Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Using Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa3cf66a-312f-4e4b-b5d8-c0532f6831df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5332001304956554\n",
      "Mean Squared Error: 0.5558915986952444\n",
      "R-squared: 0.5757877060324508\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model Performance\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "#MAE: Gives the average magnitude of errors in predictions, providing a straightforward error measure.\n",
    "#MSE: Penalizes larger errors more heavily, useful when larger errors are more problematic.\n",
    "#R-squared (R²): Indicates the proportion of variance explained by the model,close to 1 suggests a good fit, but it’s sensitive to overfitting in complex models.\n",
    "#Ridge or Lasso regularization can be applied if multicollinearity or overfitting is detected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85af9df-1a48-4d12-bab4-d2ddf261994d",
   "metadata": {},
   "source": [
    "### 8. With the `digits` dataset available in sklearn, how would you approach the classification task using both K-Nearest Neighbors and Support Vector Machine algorithms? Compare their performance using classification evaluation metrics and discuss the importance of the sigmoid function in the context of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22da10c2-be37-481a-abfc-6a1e94a40fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Digits Dataset and Prepare the Data\n",
    "# Description : The digits dataset contains 1,797 images of handwritten digits (0–9), \n",
    "# each represented as an 8x8 grid of pixel intensities, along with labels indicating the digit.\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data for SVM to perform optimally\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce317296-912b-40b2-8ab9-da88f49204b3",
   "metadata": {},
   "source": [
    "### KNN \n",
    "\n",
    "K Nearest Neighbors - Classification K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970’s as a non-parametric technique.\n",
    "\n",
    "Algorithm A case is classified by a majority vote of its neighbors, with the case being assigned to the class most common amongst its K nearest neighbors measured by a distance function. If K = 1, then the case is simply assigned to the class of its nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e573227-9456-4e37-b513-bc1e5c1b3e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.96      0.96      0.96        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       1.00      0.94      0.97        34\n",
      "           8       0.97      1.00      0.98        30\n",
      "           9       0.95      0.90      0.92        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n",
      "KNN Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "#  Implement K-Nearest Neighbors (KNN)\n",
    "# Initialize and train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a47d9d-e182-4ab2-b7b5-9c47baa099f3",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "SVM aims to find the optimal hyperplane that separates classes with the maximum margin. We’ll use the radial basis function (RBF) kernel for better performance on the non-linearly separable digits data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e247e176-8101-4c5c-9fb4-6266d7a16b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       0.96      1.00      0.98        46\n",
      "           5       0.96      0.98      0.97        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       1.00      0.94      0.97        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "SVM Accuracy: 0.9805555555555555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize and train the SVM model\n",
    "svm = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3aa6e-e90e-4671-b928-9ef178a44029",
   "metadata": {},
   "source": [
    "### Compare Performance with Classification Metrics\n",
    "\n",
    "<u>Accuracy</u>: The percentage of correctly classified samples.\n",
    "\n",
    "<u>Precision</u>: The accuracy of positive predictions.\n",
    "\n",
    "<u>Recall</u>: The ratio of correctly predicted positives to all actual positives.\n",
    "\n",
    "<u>F1-score</u>: The harmonic mean of precision and recall, useful for imbalanced datasets.\n",
    "\n",
    "KNN is simpler and can perform well when relationships are easily detectable with neighborhood voting, though it may struggle \n",
    "with high-dimensional data or large datasets due to its high memory and computation cost.\n",
    "SVM, especially with a kernel like RBF, can handle complex, high-dimensional data better, often leading to improved accuracy \n",
    "and precision on structured image data.\n",
    "\n",
    "For the digits dataset, SVM is likely to perform better than KNN due to its ability to form complex decision boundaries in \n",
    "high-dimensional spaces.\n",
    "\n",
    "The Role of the Sigmoid Function in Logistic Regression\n",
    "The sigmoid function, defined as is essential in logistic regression as it maps any real-valued input to a value between 0 and 1,\n",
    "which represents the probability of belonging to a specific class. In multi-class classification\n",
    "(like digits), logistic regression can extend to one-vs-rest or softmax approaches to handle multiple classes, and the sigmoid’s probability interpretation supports probabilistic decision-making for each class.\n",
    "\n",
    "KNN may be easier to implement but computationally expensive on large datasets, while SVM typically excels on high-dimensional data like images.\n",
    "The sigmoid function is crucial in logistic regression for converting scores to probabilities, making it fundamental to probabilistic classification decisions in binary or multi-class settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484992d-9d06-4473-8c66-4fea9b889bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
